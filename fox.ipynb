{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mykola/projects/diffusion/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# huggingface\n",
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from tqdm.auto import trange\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "text_to_im_model_id = \"stabilityai/stable-diffusion-2\"\n",
    "\n",
    "scheduler = EulerDiscreteScheduler.from_pretrained(text_to_im_model_id, subfolder=\"scheduler\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(text_to_im_model_id, scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "if text_to_im_model_id==\"stability/stable-diffusion-2\":\n",
    "    pipe.enable_attention_slicing()\n",
    "\n",
    "# image gen params\n",
    "temperature = 0.7\n",
    "max_length = 42\n",
    "guidance_scale = 7.5\n",
    "height = 768\n",
    "width = 768\n",
    "steps = 100\n",
    "num_loops = 1\n",
    "\n",
    "def makeimage(pipe, prompt):\n",
    "    prompt = \"<s>Prompt: \" + prompt + \",\"\n",
    "    for _ in trange(num_loops):\n",
    "        image = pipe(prompt, \n",
    "                    num_inference_steps=steps, \n",
    "                    height=height, width=width,\n",
    "                    guidance_scale=guidance_scale).images[0]  \n",
    "        image.save(\"output.png\")\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_profiler(pipe, prompt):\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=False) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            start_time = time.perf_counter()\n",
    "            image = makeimage(pipe, prompt)\n",
    "            final_time = time.perf_counter()\n",
    "\n",
    "    total_time = final_time - start_time\n",
    "    profiler_results = prof.key_averages()\n",
    "\n",
    "    return profiler_results, total_time, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timings(profiler_results):\n",
    "    rows = []\n",
    "    for summary in profiler_results:\n",
    "        # if summary.key != \"model_inference\":\n",
    "        #     continue\n",
    "        row = {\n",
    "            \"name\": summary.key,\n",
    "            \"cpu_time_total\": summary.cpu_time_total,\n",
    "            \"cuda_time_total\": summary.cuda_time_total,\n",
    "            \"self_cpu_time_total\": summary.self_cpu_time_total,\n",
    "            \"self_cuda_time_total\": summary.self_cuda_time_total,\n",
    "            \"cpu_memory_usage\": summary.cpu_memory_usage,\n",
    "            \"cuda_memory_usage\": summary.cuda_memory_usage,\n",
    "            \"self_cpu_memory_usage\": summary.self_cpu_memory_usage,\n",
    "            \"self_cuda_memory_usage\": summary.self_cuda_memory_usage,\n",
    "            # \"cpu_time_str\": summary.cpu_time_str,\n",
    "            # \"cuda_time_str\": summary.cuda_time_str,\n",
    "            # \"cpu_time_total_str\": summary.cpu_time_total_str,\n",
    "            # \"cuda_time_total_str\": summary.cuda_time_total_str,\n",
    "            # \"self_cpu_time_total_str\": summary.self_cpu_time_total_str,\n",
    "            # \"self_cuda_time_total_str\": summary.self_cuda_time_total_str,\n",
    "            \"cpu_time\": summary.cpu_time,\n",
    "            \"cuda_time\": summary.cuda_time,\n",
    "            \"count\": summary.count\n",
    "        }\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_profiler_info(pipe, prompt):\n",
    "    profiler_results, total_time, image = run_profiler(pipe, prompt)\n",
    "    timings_df = extract_timings(profiler_results)\n",
    "    timings_df[\"total_time\"] = total_time\n",
    "    return timings_df, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-04-17 18:40:43 6900:6900 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.09it/s]\n",
      "100%|██████████| 1/1 [00:25<00:00, 25.02s/it]\n",
      "STAGE:2023-04-17 18:41:09 6900:6900 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-04-17 18:41:09 6900:6900 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "df, image = collect_profiler_info(pipe, \"A fox in space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>cpu_time_total</th>\n",
       "      <th>cuda_time_total</th>\n",
       "      <th>self_cpu_time_total</th>\n",
       "      <th>self_cuda_time_total</th>\n",
       "      <th>cpu_memory_usage</th>\n",
       "      <th>cuda_memory_usage</th>\n",
       "      <th>self_cpu_memory_usage</th>\n",
       "      <th>self_cuda_memory_usage</th>\n",
       "      <th>cpu_time</th>\n",
       "      <th>cuda_time</th>\n",
       "      <th>count</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::to</td>\n",
       "      <td>339532</td>\n",
       "      <td>3935</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>10616836</td>\n",
       "      <td>509841920</td>\n",
       "      <td>0</td>\n",
       "      <td>14848</td>\n",
       "      <td>7.845009e+01</td>\n",
       "      <td>9.091959e-01</td>\n",
       "      <td>4328</td>\n",
       "      <td>25.023545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aten::_to_copy</td>\n",
       "      <td>339279</td>\n",
       "      <td>3963</td>\n",
       "      <td>1018</td>\n",
       "      <td>0</td>\n",
       "      <td>10616836</td>\n",
       "      <td>509841920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.592859e+03</td>\n",
       "      <td>1.860563e+01</td>\n",
       "      <td>213</td>\n",
       "      <td>25.023545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aten::empty_strided</td>\n",
       "      <td>1033</td>\n",
       "      <td>0</td>\n",
       "      <td>1033</td>\n",
       "      <td>0</td>\n",
       "      <td>10616836</td>\n",
       "      <td>509841920</td>\n",
       "      <td>10616836</td>\n",
       "      <td>509841920</td>\n",
       "      <td>4.849765e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>213</td>\n",
       "      <td>25.023545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::empty</td>\n",
       "      <td>143204</td>\n",
       "      <td>0</td>\n",
       "      <td>143204</td>\n",
       "      <td>0</td>\n",
       "      <td>25664</td>\n",
       "      <td>121264107520</td>\n",
       "      <td>25664</td>\n",
       "      <td>121264107520</td>\n",
       "      <td>2.223043e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>64418</td>\n",
       "      <td>25.023545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>aten::pow</td>\n",
       "      <td>7509</td>\n",
       "      <td>511</td>\n",
       "      <td>5038</td>\n",
       "      <td>511</td>\n",
       "      <td>4000</td>\n",
       "      <td>256000</td>\n",
       "      <td>4000</td>\n",
       "      <td>256000</td>\n",
       "      <td>1.498802e+01</td>\n",
       "      <td>1.019960e+00</td>\n",
       "      <td>501</td>\n",
       "      <td>25.023545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>aten::div</td>\n",
       "      <td>35935</td>\n",
       "      <td>68783</td>\n",
       "      <td>22910</td>\n",
       "      <td>68783</td>\n",
       "      <td>4000</td>\n",
       "      <td>12192405504</td>\n",
       "      <td>4000</td>\n",
       "      <td>12192405504</td>\n",
       "      <td>1.322598e+01</td>\n",
       "      <td>2.531579e+01</td>\n",
       "      <td>2717</td>\n",
       "      <td>25.023545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>aten::rsub</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>25.023545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>aten::sub</td>\n",
       "      <td>4156</td>\n",
       "      <td>357</td>\n",
       "      <td>2762</td>\n",
       "      <td>357</td>\n",
       "      <td>3992</td>\n",
       "      <td>14796800</td>\n",
       "      <td>3988</td>\n",
       "      <td>14796800</td>\n",
       "      <td>1.380731e+01</td>\n",
       "      <td>1.186047e+00</td>\n",
       "      <td>301</td>\n",
       "      <td>25.023545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_inference</td>\n",
       "      <td>25023598</td>\n",
       "      <td>24301476</td>\n",
       "      <td>1340525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-10654496</td>\n",
       "      <td>-553009340416</td>\n",
       "      <td>2.502360e+07</td>\n",
       "      <td>2.430148e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>25.023545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>aten::_efficient_attention_forward</td>\n",
       "      <td>53478</td>\n",
       "      <td>6354810</td>\n",
       "      <td>22408</td>\n",
       "      <td>6354810</td>\n",
       "      <td>0</td>\n",
       "      <td>21263155200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.671187e+01</td>\n",
       "      <td>1.985878e+03</td>\n",
       "      <td>3200</td>\n",
       "      <td>25.023545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name  cpu_time_total  cuda_time_total   \n",
       "2                              aten::to          339532             3935  \\\n",
       "6                        aten::_to_copy          339279             3963   \n",
       "7                   aten::empty_strided            1033                0   \n",
       "1                           aten::empty          143204                0   \n",
       "76                            aten::pow            7509              511   \n",
       "75                            aten::div           35935            68783   \n",
       "73                           aten::rsub              23                0   \n",
       "74                            aten::sub            4156              357   \n",
       "0                       model_inference        25023598         24301476   \n",
       "143  aten::_efficient_attention_forward           53478          6354810   \n",
       "\n",
       "     self_cpu_time_total  self_cuda_time_total  cpu_memory_usage   \n",
       "2                    600                     0          10616836  \\\n",
       "6                   1018                     0          10616836   \n",
       "7                   1033                     0          10616836   \n",
       "1                 143204                     0             25664   \n",
       "76                  5038                   511              4000   \n",
       "75                 22910                 68783              4000   \n",
       "73                     6                     0              4000   \n",
       "74                  2762                   357              3992   \n",
       "0                1340525                     0                 0   \n",
       "143                22408               6354810                 0   \n",
       "\n",
       "     cuda_memory_usage  self_cpu_memory_usage  self_cuda_memory_usage   \n",
       "2            509841920                      0                   14848  \\\n",
       "6            509841920                      0                       0   \n",
       "7            509841920               10616836               509841920   \n",
       "1         121264107520                  25664            121264107520   \n",
       "76              256000                   4000                  256000   \n",
       "75         12192405504                   4000             12192405504   \n",
       "73                   0                      8                       0   \n",
       "74            14796800                   3988                14796800   \n",
       "0                    0              -10654496           -553009340416   \n",
       "143        21263155200                      0                       0   \n",
       "\n",
       "         cpu_time     cuda_time  count  total_time  \n",
       "2    7.845009e+01  9.091959e-01   4328   25.023545  \n",
       "6    1.592859e+03  1.860563e+01    213   25.023545  \n",
       "7    4.849765e+00  0.000000e+00    213   25.023545  \n",
       "1    2.223043e+00  0.000000e+00  64418   25.023545  \n",
       "76   1.498802e+01  1.019960e+00    501   25.023545  \n",
       "75   1.322598e+01  2.531579e+01   2717   25.023545  \n",
       "73   2.300000e+01  0.000000e+00      1   25.023545  \n",
       "74   1.380731e+01  1.186047e+00    301   25.023545  \n",
       "0    2.502360e+07  2.430148e+07      1   25.023545  \n",
       "143  1.671187e+01  1.985878e+03   3200   25.023545  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by cpu_time_total\n",
    "# df.sort_values(by=\"cpu_time_total\", ascending=False)[:10]\n",
    "\n",
    "# sort by total cpu memory\n",
    "df.sort_values(by=\"cpu_memory_usage\", ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-04-17 18:15:21 4006:4006 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.12it/s]\n",
      "100%|██████████| 1/1 [00:24<00:00, 24.77s/it]\n",
      "STAGE:2023-04-17 18:15:46 4006:4006 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-04-17 18:15:46 4006:4006 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "profiler_results, total_time, image=run_profiler(pipe, \"A fox in space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         5.03%        1.245s       100.00%       24.768s       24.768s       0.000us         0.00%       24.119s       24.119s           0 b     -10.15 Mb           0 b    -519.98 Gb             1  \n",
      "                                        cudaMemcpyAsync        83.20%       20.607s        83.20%       20.607s      33.838ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           609  \n",
      "                                          aten::nonzero         0.03%       7.800ms        81.91%       20.288s     101.441ms       1.044ms         0.00%       1.044ms       5.220us           0 b           0 b     100.50 Kb      12.50 Kb           200  \n",
      "                                           aten::conv2d         0.03%       8.216ms         4.06%        1.006s     151.538us       0.000us         0.00%       10.251s       1.545ms           0 b           0 b      37.20 Gb    -153.78 Mb          6636  \n",
      "                                      aten::convolution         0.08%      20.583ms         4.03%     997.452ms     150.309us       0.000us         0.00%       10.253s       1.545ms           0 b           0 b      37.20 Gb     754.42 Mb          6636  \n",
      "                                     aten::_convolution         0.17%      42.567ms         3.97%     983.213ms     148.164us       0.000us         0.00%       10.355s       1.560ms           0 b           0 b      37.20 Gb           0 b          6636  \n",
      "                                aten::cudnn_convolution         0.81%     200.085ms         3.44%     851.484ms     128.313us       10.058s        41.70%       10.058s       1.516ms           0 b           0 b      37.20 Gb      37.20 Gb          6636  \n",
      "                                           aten::linear         0.34%      84.766ms         3.24%     801.684ms      36.640us       0.000us         0.00%        4.423s     202.134us           0 b           0 b     170.51 Gb       2.50 Gb         21880  \n",
      "                                        cudaMemsetAsync         2.19%     543.417ms         2.19%     543.417ms      83.346us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          6520  \n",
      "                                       cudaLaunchKernel         2.00%     496.104ms         2.00%     496.104ms       4.465us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b        111116  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 24.768s\n",
      "Self CUDA time total: 24.120s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(profiler_results.table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = 'A man in space'\n",
    "\n",
    "# start_time = time.perf_counter()\n",
    "\n",
    "# with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=False) as prof:\n",
    "#     with record_function(\"model_inference\"):\n",
    "#         image = makeimage(pipe, prompt)\n",
    "\n",
    "#         final_time = time.perf_counter()\n",
    "\n",
    "# pforiler_results = prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)\n",
    "\n",
    "# # print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "# print(pforiler_results)\n",
    "\n",
    "# total_time = final_time - start_time\n",
    "# print(f\"Total time: {total_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof.key_averages().table(row_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to pandas dataframe\n",
    "# import pandas as pd\n",
    "# df = prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10).to_pandas()\n",
    "\n",
    "# # the previous method didn't work, so try this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pforiler_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prof.key_averages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # import StringIO\n",
    "# from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(StringIO(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summaries = prof.key_averages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = []\n",
    "# for summary in summaries:\n",
    "#     name = summary.key\n",
    "#     cpu_time_total = summary.cpu_time_total\n",
    "#     cuda_time_total = summary.cuda_time_total\n",
    "#     self_cpu_time_total = summary.self_cpu_time_total\n",
    "#     self_cuda_time_total = summary.self_cuda_time_total\n",
    "#     cpu_memory_usage = summary.cpu_memory_usage\n",
    "#     cuda_memory_usage = summary.cuda_memory_usage\n",
    "#     self_cpu_memory_usage = summary.self_cpu_memory_usage\n",
    "#     self_cuda_memory_usage = summary.self_cuda_memory_usage\n",
    "#     cpu_time_str = summary.cpu_time_str\n",
    "#     cuda_time_str = summary.cuda_time_str\n",
    "#     cpu_time_total_str = summary.cpu_time_total_str\n",
    "#     cuda_time_total_str = summary.cuda_time_total_str\n",
    "#     self_cpu_time_total_str = summary.self_cpu_time_total_str\n",
    "#     self_cuda_time_total_str = summary.self_cuda_time_total_str\n",
    "#     cpu_time = summary.cpu_time\n",
    "#     cuda_time = summary.cuda_time\n",
    "#     count = summary.count\n",
    "    \n",
    "#     row = {\n",
    "#         \"name\": name,\n",
    "#         \"cpu_time_total\": cpu_time_total,\n",
    "#         \"cuda_time_total\": cuda_time_total,\n",
    "#         \"self_cpu_time_total\": self_cpu_time_total,\n",
    "#         \"self_cuda_time_total\": self_cuda_time_total,\n",
    "#         \"cpu_memory_usage\": cpu_memory_usage,\n",
    "#         \"cuda_memory_usage\": cuda_memory_usage,\n",
    "#         \"self_cpu_memory_usage\": self_cpu_memory_usage,\n",
    "#         \"self_cuda_memory_usage\": self_cuda_memory_usage,\n",
    "#         \"cpu_time_str\": cpu_time_str,\n",
    "#         \"cuda_time_str\": cuda_time_str,\n",
    "#         \"cpu_time_total_str\": cpu_time_total_str,\n",
    "#         \"cuda_time_total_str\": cuda_time_total_str,\n",
    "#         \"self_cpu_time_total_str\": self_cpu_time_total_str,\n",
    "#         \"self_cuda_time_total_str\": self_cuda_time_total_str,\n",
    "#         \"cpu_time\": cpu_time,\n",
    "#         \"cuda_time\": cuda_time,\n",
    "#         \"count\": count\n",
    "#     }\n",
    "#     rows.append(row)\n",
    "\n",
    "#     # dirs = summary.__dir__()\n",
    "#     # for dir in dirs:\n",
    "#     #     if not dir.startswith(\"_\"):\n",
    "#     #         print(dir, getattr(summary, dir))\n",
    "#     # break\n",
    "\n",
    "# df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_timings(profiler_results):\n",
    "#     rows = []\n",
    "#     for summary in profiler_results:\n",
    "#         row = {\n",
    "#             \"name\": summary.key,\n",
    "#             \"cpu_time_total\": summary.cpu_time_total,\n",
    "#             \"cuda_time_total\": summary.cuda_time_total,\n",
    "#             \"self_cpu_time_total\": summary.self_cpu_time_total,\n",
    "#             \"self_cuda_time_total\": summary.self_cuda_time_total,\n",
    "#             \"cpu_memory_usage\": summary.cpu_memory_usage,\n",
    "#             \"cuda_memory_usage\": summary.cuda_memory_usage,\n",
    "#             \"self_cpu_memory_usage\": summary.self_cpu_memory_usage,\n",
    "#             \"self_cuda_memory_usage\": summary.self_cuda_memory_usage,\n",
    "#             \"cpu_time_str\": summary.cpu_time_str,\n",
    "#             \"cuda_time_str\": summary.cuda_time_str,\n",
    "#             \"cpu_time_total_str\": summary.cpu_time_total_str,\n",
    "#             \"cuda_time_total_str\": summary.cuda_time_total_str,\n",
    "#             \"self_cpu_time_total_str\": summary.self_cpu_time_total_str,\n",
    "#             \"self_cuda_time_total_str\": summary.self_cuda_time_total_str,\n",
    "#             \"cpu_time\": summary.cpu_time,\n",
    "#             \"cuda_time\": summary.cuda_time,\n",
    "#             \"count\": summary.count\n",
    "#         }\n",
    "#         rows.append(row)\n",
    "#     return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"profile.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<FunctionEventAvg key=model_inference self_cpu_time=1.211s cpu_time=25.415s  self_cuda_time=0.000us cuda_time=27.438s input_shapes= cpu_memory_usage=0 cuda_memory_usage=8521216>,\n",
       " <FunctionEventAvg key=aten::empty self_cpu_time=149.071ms cpu_time=2.324us  self_cuda_time=0.000us cuda_time=0.032us input_shapes= cpu_memory_usage=26376 cuda_memory_usage=123099233280>,\n",
       " <FunctionEventAvg key=aten::to self_cpu_time=800.000us cpu_time=67.830us  self_cuda_time=0.000us cuda_time=1.867us input_shapes= cpu_memory_usage=10616836 cuda_memory_usage=509841920>,\n",
       " <FunctionEventAvg key=aten::lift_fresh self_cpu_time=1.000us cpu_time=0.100us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::detach_ self_cpu_time=11.000us cpu_time=1.750us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=detach_ self_cpu_time=3.000us cpu_time=0.375us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::_to_copy self_cpu_time=1.010ms cpu_time=1.377ms  self_cuda_time=0.000us cuda_time=39.070us input_shapes= cpu_memory_usage=10616836 cuda_memory_usage=509841920>,\n",
       " <FunctionEventAvg key=aten::empty_strided self_cpu_time=1.054ms cpu_time=6.042us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=10616832 cuda_memory_usage=509841920>,\n",
       " <FunctionEventAvg key=aten::copy_ self_cpu_time=16.325ms cpu_time=156.834us  self_cuda_time=190.585ms cuda_time=115.869us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaMemcpyAsync self_cpu_time=20.553s cpu_time=33.749ms  self_cuda_time=10.086ms cuda_time=16.788us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaStreamSynchronize self_cpu_time=1.225ms cpu_time=2.018us  self_cuda_time=11.983ms cuda_time=19.741us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=Memcpy HtoD (Pageable -> Device) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=3.000us cuda_time=0.500us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::view self_cpu_time=16.703ms cpu_time=0.275us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::slice self_cpu_time=12.409ms cpu_time=1.496us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::as_strided self_cpu_time=5.750ms cpu_time=0.085us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::embedding self_cpu_time=46.000us cpu_time=69.250us  self_cuda_time=0.000us cuda_time=4.250us input_shapes= cpu_memory_usage=0 cuda_memory_usage=630784>,\n",
       " <FunctionEventAvg key=aten::reshape self_cpu_time=53.393ms cpu_time=2.473us  self_cuda_time=0.000us cuda_time=0.037us input_shapes= cpu_memory_usage=0 cuda_memory_usage=7254016>,\n",
       " <FunctionEventAvg key=aten::_reshape_alias self_cpu_time=11.807ms cpu_time=0.457us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::index_select self_cpu_time=85.000us cpu_time=52.250us  self_cuda_time=17.000us cuda_time=4.250us input_shapes= cpu_memory_usage=0 cuda_memory_usage=630784>,\n",
       " <FunctionEventAvg key=aten::resize_ self_cpu_time=1.563ms cpu_time=5.108us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=835072>,\n",
       " <FunctionEventAvg key=cudaLaunchKernel self_cpu_time=759.139ms cpu_time=6.832us  self_cuda_time=2.122s cuda_time=19.185us input_shapes= cpu_memory_usage=-168 cuda_memory_usage=1132032>,\n",
       " <FunctionEventAvg key=aten::add self_cpu_time=100.129ms cpu_time=12.998us  self_cuda_time=542.077ms cuda_time=63.611us input_shapes= cpu_memory_usage=0 cuda_memory_usage=67226000384>,\n",
       " <FunctionEventAvg key=aten::fill_ self_cpu_time=26.000us cpu_time=16.500us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::item self_cpu_time=1.562ms cpu_time=63.114us  self_cuda_time=0.000us cuda_time=45.137us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::_local_scalar_dense self_cpu_time=1.324ms cpu_time=61.883us  self_cuda_time=42.000us cuda_time=45.139us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::triu_ self_cpu_time=664.000us cpu_time=332.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::(anonymous namespace)::indexSelectLargeIndex<c10::Half, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<c10::Half, unsigned int>, at::cuda::detail::TensorInfo<c10::Half, unsigned int>, at::cuda::detail::TensorInfo<long, unsigned int>, int, int, unsigned int, unsigned int, long) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=17.000us cuda_time=4.250us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=454.711ms cuda_time=49.404us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::unsqueeze self_cpu_time=4.006ms cpu_time=0.854us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::layer_norm self_cpu_time=9.415ms cpu_time=25.739us  self_cuda_time=0.000us cuda_time=91.231us input_shapes= cpu_memory_usage=0 cuda_memory_usage=33484660736>,\n",
       " <FunctionEventAvg key=aten::native_layer_norm self_cpu_time=59.282ms cpu_time=23.815us  self_cuda_time=358.472ms cuda_time=91.231us input_shapes= cpu_memory_usage=0 cuda_memory_usage=33689737216>,\n",
       " <FunctionEventAvg key=void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<c10::Half, float>(int, float, c10::Half const*, c10::Half const*, c10::Half const*, float*, float*, c10::Half*) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=358.472ms cuda_time=73.247us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::linear self_cpu_time=78.287ms cpu_time=49.123us  self_cuda_time=0.000us cuda_time=247.696us input_shapes= cpu_memory_usage=0 cuda_memory_usage=183093833728>,\n",
       " <FunctionEventAvg key=aten::t self_cpu_time=37.429ms cpu_time=2.895us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::transpose self_cpu_time=45.377ms cpu_time=1.018us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::addmm self_cpu_time=249.492ms cpu_time=57.882us  self_cuda_time=3.157s cuda_time=351.563us input_shapes= cpu_memory_usage=0 cuda_memory_usage=127251959808>,\n",
       " <FunctionEventAvg key=cudaStreamIsCapturing self_cpu_time=112.000us cpu_time=0.017us  self_cuda_time=164.169ms cuda_time=24.282us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaMalloc self_cpu_time=3.667ms cpu_time=118.290us  self_cuda_time=10.163ms cuda_time=327.839us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaFree self_cpu_time=276.135ms cpu_time=69.034ms  self_cuda_time=16.000us cuda_time=4.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaDeviceGetAttribute self_cpu_time=109.000us cpu_time=0.172us  self_cuda_time=13.378ms cuda_time=21.147us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaGetSymbolAddress self_cpu_time=1.000us cpu_time=1.000us  self_cuda_time=3.000us cuda_time=3.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaFuncSetAttribute self_cpu_time=3.000us cpu_time=0.028us  self_cuda_time=240.000us cuda_time=2.222us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaOccupancyMaxActiveBlocksPerMultiprocessor self_cpu_time=2.171ms cpu_time=0.106us  self_cuda_time=390.970ms cuda_time=19.105us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_128x128_ldg8_f2f_tn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=882.129ms cuda_time=141.571us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void splitKreduce_kernel<32, 16, int, __half, __half, float, __half, true, true, false>(cublasSplitKParams<float>, __half const*, __half const*, __half*, float const*, float const*, __half const*, __half const*, __half*, void*, long, float*, int*) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=946.000us cuda_time=4.113us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::mul self_cpu_time=21.133ms cpu_time=13.103us  self_cuda_time=386.538ms cuda_time=177.277us input_shapes= cpu_memory_usage=0 cuda_memory_usage=42222876672>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=297.000us cuda_time=1.198us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::contiguous self_cpu_time=5.689ms cpu_time=20.941us  self_cuda_time=0.000us cuda_time=104.745us input_shapes= cpu_memory_usage=0 cuda_memory_usage=11566649344>,\n",
       " <FunctionEventAvg key=aten::clone self_cpu_time=4.950ms cpu_time=20.180us  self_cuda_time=0.000us cuda_time=123.340us input_shapes= cpu_memory_usage=0 cuda_memory_usage=11573903360>,\n",
       " <FunctionEventAvg key=aten::empty_like self_cpu_time=2.016ms cpu_time=4.695us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=11573903360>,\n",
       " <FunctionEventAvg key=void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=186.612ms cuda_time=104.311us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::bmm self_cpu_time=26.963ms cpu_time=21.177us  self_cuda_time=247.020ms cuda_time=183.462us input_shapes= cpu_memory_usage=0 cuda_memory_usage=11393106944>,\n",
       " <FunctionEventAvg key=cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags self_cpu_time=2.370ms cpu_time=0.455us  self_cuda_time=116.989ms cuda_time=22.442us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void cutlass::Kernel<cutlass_75_wmma_tensorop_f16_s161616gemm_f16_16x16_64x1_tn_align1>(cutlass_75_wmma_tensorop_f16_s161616gemm_f16_16x16_64x1_tn_align1::Params) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=506.000us cuda_time=11.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=500.860ms cuda_time=47.746us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::softmax self_cpu_time=61.000us cpu_time=18.149us  self_cuda_time=0.000us cuda_time=232.277us input_shapes= cpu_memory_usage=0 cuda_memory_usage=348476416>,\n",
       " <FunctionEventAvg key=aten::_softmax self_cpu_time=362.000us cpu_time=16.851us  self_cuda_time=3.601ms cuda_time=232.277us input_shapes= cpu_memory_usage=0 cuda_memory_usage=348476416>,\n",
       " <FunctionEventAvg key=void (anonymous namespace)::softmax_warp_forward<c10::Half, c10::Half, float, 7, false, false>(c10::Half*, c10::Half const*, int, int, int, bool const*, int, bool) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=184.000us cuda_time=4.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::dropout self_cpu_time=6.000us cpu_time=0.001us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void cutlass::Kernel<cutlass_75_wmma_tensorop_f16_s161616gemm_f16_16x16_64x1_nn_align1>(cutlass_75_wmma_tensorop_f16_s161616gemm_f16_16x16_64x1_nn_align1::Params) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=644.000us cuda_time=14.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::_unsafe_view self_cpu_time=4.181ms cpu_time=0.372us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_128x128_ldg8_relu_f2f_tn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=1.470s cuda_time=323.348us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::gelu self_cpu_time=17.968ms cpu_time=16.135us  self_cuda_time=376.275ms cuda_time=238.649us input_shapes= cpu_memory_usage=0 cuda_memory_usage=42450468864>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=184.000us cuda_time=4.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::arange self_cpu_time=1.039ms cpu_time=18.417us  self_cuda_time=102.000us cuda_time=2.544us input_shapes= cpu_memory_usage=0 cuda_memory_usage=206848>,\n",
       " <FunctionEventAvg key=void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=2.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(int)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1> >(int, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(int)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=4.000us cuda_time=2.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::argmax self_cpu_time=34.000us cpu_time=22.500us  self_cuda_time=12.000us cuda_time=6.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=1024>,\n",
       " <FunctionEventAvg key=void at::native::reduce_kernel<512, 1, at::native::ReduceOp<int, at::native::ArgMaxOps<int>, unsigned int, long, 4> >(at::native::ReduceOp<int, at::native::ArgMaxOps<int>, unsigned int, long, 4>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=12.000us cuda_time=6.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::index self_cpu_time=49.000us cpu_time=32.500us  self_cuda_time=12.000us cuda_time=6.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=4096>,\n",
       " <FunctionEventAvg key=void at::native::index_elementwise_kernel<128, 4, at::native::gpu_index_kernel<at::native::index_kernel_impl<at::native::OpaqueType<2> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_kernel_impl<at::native::OpaqueType<2> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char*, long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_index_kernel<at::native::index_kernel_impl<at::native::OpaqueType<2> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_kernel_impl<at::native::OpaqueType<2> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char*, long)#1} const&)::{lambda(int)#1}) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=12.000us cuda_time=6.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::repeat self_cpu_time=38.000us cpu_time=48.500us  self_cuda_time=0.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=315392>,\n",
       " <FunctionEventAvg key=aten::expand self_cpu_time=3.991ms cpu_time=1.209us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::alias self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::unfold self_cpu_time=5.000us cpu_time=0.833us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::expand_as self_cpu_time=0.000us cpu_time=1.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=Memcpy DtoD (Device -> Device) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=2.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::cat self_cpu_time=16.801ms cpu_time=16.431us  self_cuda_time=100.349ms cuda_time=85.200us input_shapes= cpu_memory_usage=0 cuda_memory_usage=14279483392>,\n",
       " <FunctionEventAvg key=void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 3, 128, 1>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=4.000us cuda_time=4.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::rsub self_cpu_time=6.000us cpu_time=21.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=4000 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::sub self_cpu_time=3.600ms cpu_time=16.256us  self_cuda_time=305.000us cuda_time=21.877us input_shapes= cpu_memory_usage=4004 cuda_memory_usage=14796800>,\n",
       " <FunctionEventAvg key=aten::div self_cpu_time=22.988ms cpu_time=12.498us  self_cuda_time=68.517ms cuda_time=42.188us input_shapes= cpu_memory_usage=4000 cuda_memory_usage=12428204032>,\n",
       " <FunctionEventAvg key=aten::pow self_cpu_time=4.761ms cpu_time=14.110us  self_cuda_time=507.000us cuda_time=35.525us input_shapes= cpu_memory_usage=4000 cuda_memory_usage=256000>,\n",
       " <FunctionEventAvg key=aten::result_type self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::detach self_cpu_time=6.000us cpu_time=5.500us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=detach self_cpu_time=5.000us cpu_time=2.500us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::resolve_conj self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::resolve_neg self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::randn self_cpu_time=589.000us cpu_time=30.653us  self_cuda_time=0.000us cuda_time=36.950us input_shapes= cpu_memory_usage=0 cuda_memory_usage=7446528>,\n",
       " <FunctionEventAvg key=aten::normal_ self_cpu_time=1.308ms cpu_time=20.248us  self_cuda_time=308.000us cuda_time=37.010us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::(anonymous namespace)::distribution_elementwise_grid_stride_kernel<float, 4, at::native::templates::cuda::normal_and_transform<c10::Half, float, 4ul, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1})::{lambda(curandStatePhilox4_32_10*)#2}, at::native::(anonymous namespace)::distribution_nullary_kernel<c10::Half, float, 4, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_and_transform<c10::Half, float, 4ul, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1})::{lambda(curandStatePhilox4_32_10*)#2}, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_and_transform<c10::Half, float, 4ul, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1})::{lambda(curandStatePhilox4_32_10*)#2} const&, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1})::{lambda(int, float)#1}>(int, at::PhiloxCudaState, at::native::templates::cuda::normal_and_transform<c10::Half, float, 4ul, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1})::{lambda(curandStatePhilox4_32_10*)#2}, at::native::(anonymous namespace)::distribution_nullary_kernel<c10::Half, float, 4, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_and_transform<c10::Half, float, 4ul, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1})::{lambda(curandStatePhilox4_32_10*)#2}, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_and_transform<c10::Half, float, 4ul, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1})::{lambda(curandStatePhilox4_32_10*)#2} const&, at::native::templates::cuda::normal_kernel<at::CUDAGeneratorImpl*>(at::TensorBase const&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(float)#1})::{lambda(int, float)#1}) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=308.000us cuda_time=3.050us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::unbind self_cpu_time=98.000us cpu_time=102.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::select self_cpu_time=1.673ms cpu_time=4.207us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::(anonymous namespace)::CatArrayBatchedCopy<c10::Half, unsigned int, 4, 128, 1>(c10::Half*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<c10::Half, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=99.942ms cuda_time=76.878us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::eq self_cpu_time=2.339ms cpu_time=59.960us  self_cuda_time=400.000us cuda_time=24.690us input_shapes= cpu_memory_usage=0 cuda_memory_usage=102400>,\n",
       " <FunctionEventAvg key=void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<double, double, bool, at::native::(anonymous namespace)::CompareEqFunctor<double> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<double, double, bool, at::native::(anonymous namespace)::CompareEqFunctor<double> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<double, double, bool, at::native::(anonymous namespace)::CompareEqFunctor<double> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<double, double, bool, at::native::(anonymous namespace)::CompareEqFunctor<double> > const&)::{lambda(int)#1}) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=400.000us cuda_time=2.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::nonzero self_cpu_time=7.255ms cpu_time=101.380ms  self_cuda_time=1.007ms cuda_time=222.220us input_shapes= cpu_memory_usage=0 cuda_memory_usage=102400>,\n",
       " <FunctionEventAvg key=cudaGetDeviceCount self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaFuncGetAttributes self_cpu_time=293.000us cpu_time=2.901us  self_cuda_time=378.000us cuda_time=56.881us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaPeekAtLastError self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=26.780ms cuda_time=22.317us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at_cuda_detail::cub::DeviceReduceSingleTileKernel<at_cuda_detail::cub::DeviceReducePolicy<bool, int, int, at_cuda_detail::cub::Sum>::Policy600, at_cuda_detail::cub::TransformInputIterator<bool, at::native::(anonymous namespace)::NonZeroOp<bool>, bool*, long>, int*, int, at_cuda_detail::cub::Sum, int>(at_cuda_detail::cub::TransformInputIterator<bool, at::native::(anonymous namespace)::NonZeroOp<bool>, bool*, long>, int*, int, at_cuda_detail::cub::Sum, int) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=358.000us cuda_time=1.790us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=Memcpy DtoH (Device -> Pageable) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=846.000us cuda_time=1.408us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, true>, int*>(at_cuda_detail::cub::ScanTileState<int, true>, int, int*) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=201.000us cuda_time=1.005us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at_cuda_detail::cub::DeviceSelectSweepKernel<at_cuda_detail::cub::DispatchSelectIf<at_cuda_detail::cub::CountingInputIterator<long, long>, at_cuda_detail::cub::TransformInputIterator<bool, at::native::(anonymous namespace)::NonZeroOp<bool>, bool*, long>, long*, int*, at_cuda_detail::cub::NullType, at_cuda_detail::cub::NullType, int, false>::PtxSelectIfPolicyT, at_cuda_detail::cub::CountingInputIterator<long, long>, at_cuda_detail::cub::TransformInputIterator<bool, at::native::(anonymous namespace)::NonZeroOp<bool>, bool*, long>, long*, int*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::NullType, at_cuda_detail::cub::NullType, int, false>(at_cuda_detail::cub::CountingInputIterator<long, long>, at_cuda_detail::cub::TransformInputIterator<bool, at::native::(anonymous namespace)::NonZeroOp<bool>, bool*, long>, long*, int*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::NullType, at_cuda_detail::cub::NullType, int, int) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=408.000us cuda_time=2.040us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::set_ self_cpu_time=343.000us cpu_time=1.089us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=75.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=305.000us cuda_time=1.017us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::sqrt_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::sqrt_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=205.000us cuda_time=1.025us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#2}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#2}) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=1.316ms cuda_time=4.387us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(long)#1}>::result_type*) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=100.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=227.000us cuda_time=1.009us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=103.000us cuda_time=1.030us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::exp self_cpu_time=834.000us cpu_time=12.270us  self_cuda_time=107.000us cuda_time=2.720us input_shapes= cpu_memory_usage=0 cuda_memory_usage=102400>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::exp_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::exp_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=107.000us cuda_time=1.070us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#2}>(int, at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#2}) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=200.000us cuda_time=2.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=200.000us cuda_time=2.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::sin self_cpu_time=845.000us cpu_time=12.940us  self_cuda_time=200.000us cuda_time=15.670us input_shapes= cpu_memory_usage=0 cuda_memory_usage=153600>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::sin_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::sin_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=200.000us cuda_time=2.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::cos self_cpu_time=833.000us cpu_time=12.910us  self_cuda_time=200.000us cuda_time=16.320us input_shapes= cpu_memory_usage=0 cuda_memory_usage=153600>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::cos_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::cos_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=200.000us cuda_time=2.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 2, 128, 1>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=200.000us cuda_time=2.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::(anonymous namespace)::CatArrayBatchedCopy<float, unsigned int, 2, 64, 64>(float*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<float, unsigned int, 64, 64>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=203.000us cuda_time=2.030us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1> >(int, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=1.600ms cuda_time=15.842us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, true, cublasGemvTensorStridedBatched<__half const>, cublasGemvTensorStridedBatched<__half const>, cublasGemvTensorStridedBatched<__half> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<__half const>, cublasGemvTensorStridedBatched<__half const>, cublasGemvTensorStridedBatched<__half>, float>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=542.000us cuda_time=5.420us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::silu self_cpu_time=55.409ms cpu_time=12.306us  self_cuda_time=193.753ms cuda_time=49.773us input_shapes= cpu_memory_usage=0 cuda_memory_usage=33521446912>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::silu_kernel(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::silu_kernel(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=193.753ms cuda_time=28.372us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void cutlass::Kernel<cutlass_75_wmma_tensorop_f16_s161616gemm_f16_16x16_128x2_tn_align8>(cutlass_75_wmma_tensorop_f16_s161616gemm_f16_16x16_128x2_tn_align8::Params) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=27.960ms cuda_time=12.157us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::conv2d self_cpu_time=7.260ms cpu_time=223.511us  self_cuda_time=0.000us cuda_time=1.725ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=39936663552>,\n",
       " <FunctionEventAvg key=aten::convolution self_cpu_time=21.752ms cpu_time=222.334us  self_cuda_time=0.000us cuda_time=1.712ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=39936663552>,\n",
       " <FunctionEventAvg key=aten::_convolution self_cpu_time=41.623ms cpu_time=220.293us  self_cuda_time=0.000us cuda_time=1.738ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=39936663552>,\n",
       " <FunctionEventAvg key=aten::cudnn_convolution self_cpu_time=329.172ms cpu_time=200.479us  self_cuda_time=10.098s cuda_time=1.671ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=39936663552>,\n",
       " <FunctionEventAvg key=cudaDriverGetVersion self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaGetDeviceProperties self_cpu_time=76.000us cpu_time=76.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaStreamCreateWithFlags self_cpu_time=62.978ms cpu_time=3.936ms  self_cuda_time=153.000us cuda_time=9.562us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaMemsetAsync self_cpu_time=580.286ms cpu_time=88.987us  self_cuda_time=118.078ms cuda_time=18.107us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaHostAlloc self_cpu_time=509.000us cpu_time=509.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=Memset (Device) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=379.000us cuda_time=0.090us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaHostGetDevicePointer self_cpu_time=1.000us cpu_time=1.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaStreamGetPriority self_cpu_time=4.000us cpu_time=0.001us  self_cuda_time=121.344ms cuda_time=18.286us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaDeviceGetStreamPriorityRange self_cpu_time=1.000us cpu_time=0.000us  self_cuda_time=115.846ms cuda_time=17.457us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void implicit_convolve_sgemm<__half, __half, 1024, 5, 5, 3, 3, 3, 1, false, false, true>(int, int, int, __half const*, int, __half*, __half const*, kernel_conv_params, unsigned long long, int, float, float, int, __half const*, __half const*, bool, int, int) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=14.566ms cuda_time=144.218us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::add_ self_cpu_time=57.060ms cpu_time=10.611us  self_cuda_time=413.614ms cuda_time=70.153us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::group_norm self_cpu_time=14.966ms cpu_time=47.038us  self_cuda_time=0.000us cuda_time=166.463us input_shapes= cpu_memory_usage=0 cuda_memory_usage=45114942976>,\n",
       " <FunctionEventAvg key=aten::native_group_norm self_cpu_time=136.128ms cpu_time=44.580us  self_cuda_time=674.141ms cuda_time=166.369us input_shapes= cpu_memory_usage=0 cuda_memory_usage=45100383744>,\n",
       " <FunctionEventAvg key=void at::native::(anonymous namespace)::RowwiseMomentsCUDAKernel<c10::Half>(long, c10::Half, c10::Half const*, c10::Half*, c10::Half*) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=335.584ms cuda_time=54.745us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::(anonymous namespace)::ComputeFusedParamsCUDAKernel<c10::Half>(long, long, long, c10::Half const*, c10::Half const*, c10::Half const*, c10::Half const*, at::AccumulateType<c10::Half, true>::type*, at::AccumulateType<c10::Half, true>::type*) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=12.467ms cuda_time=2.034us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::GroupNormKernelImplInternal<c10::Half>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, c10::Half, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(c10::Half, float, float)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::GroupNormKernelImplInternal<c10::Half>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, c10::Half, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(c10::Half, float, float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::GroupNormKernelImplInternal<c10::Half>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, c10::Half, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(c10::Half, float, float)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::GroupNormKernelImplInternal<c10::Half>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, c10::Half, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(c10::Half, float, float)#1} const&)::{lambda(int)#1}) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=326.090ms cuda_time=53.196us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void cudnn::ops::nchwToNhwcKernel<__half, __half, float, false, true, (cudnnKernelDataType_t)0>(cudnn::ops::nchw2nhwc_params_t<float>, __half const*, __half*) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=1.734s cuda_time=165.724us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void cask_cudnn::computeOffsetsKernel<false, false>(cask_cudnn::ComputeOffsetsParams) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=4.647ms cuda_time=2.004us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudnn_turing_fp16_s1688cudnn_fp16_256x128_ldg8_relu_f2f_exp_medium_nhwc_tn_v1 self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=4.480s cuda_time=2.019ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::permute self_cpu_time=6.642ms cpu_time=2.574us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::matmul self_cpu_time=50.977ms cpu_time=26.437us  self_cuda_time=0.000us cuda_time=142.366us input_shapes= cpu_memory_usage=0 cuda_memory_usage=55841873920>,\n",
       " <FunctionEventAvg key=aten::mm self_cpu_time=129.043ms cpu_time=18.516us  self_cuda_time=963.076ms cuda_time=135.628us input_shapes= cpu_memory_usage=0 cuda_memory_usage=44474195968>,\n",
       " <FunctionEventAvg key=void cudnn::ops::nhwcToNchwKernel<__half, __half, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, __half const*, __half*) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=185.141ms cuda_time=34.083us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::scaled_dot_product_attention self_cpu_time=15.505ms cpu_time=29.099us  self_cuda_time=0.000us cuda_time=1.975ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=21263941632>,\n",
       " <FunctionEventAvg key=aten::_scaled_dot_product_efficient_attention self_cpu_time=20.950ms cpu_time=24.865us  self_cuda_time=0.000us cuda_time=2.001ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=21263941632>,\n",
       " <FunctionEventAvg key=aten::_efficient_attention_forward self_cpu_time=22.827ms cpu_time=16.677us  self_cuda_time=6.324s cuda_time=2.001ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=21263941632>,\n",
       " <FunctionEventAvg key=aten::chunk self_cpu_time=2.428ms cpu_time=8.633us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::split self_cpu_time=5.221ms cpu_time=7.434us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::narrow self_cpu_time=5.232ms cpu_time=2.116us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=66.993ms cuda_time=30.231us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tt self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=241.746ms cuda_time=151.091us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void attention_kernel_batched<AttentionKernel<cutlass::half_t, cutlass::arch::Sm75, true, 64l, 64l, true> >(AttentionKernel<cutlass::half_t, cutlass::arch::Sm75, true, 64l, 64l, true>::Params) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=6.324s cuda_time=1.976ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=INVALID self_cpu_time=22.178ms cpu_time=6.903us  self_cuda_time=76.368ms cuda_time=23.768us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=11.738ms cuda_time=11.738us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void splitKreduce_kernel<32, 16, int, __half, __half, float, __half, true, false, false>(cublasSplitKParams<float>, __half const*, __half const*, __half*, float const*, float const*, __half const*, __half const*, __half*, void*, long, float*, int*) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=3.001ms cuda_time=3.001us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::GeluCUDAKernelImpl(at::TensorIteratorBase&, at::native::GeluType)::{lambda()#2}::operator()() const::{lambda()#3}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=376.091ms cuda_time=235.057us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=384.908ms cuda_time=240.567us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::upsample_nearest2d self_cpu_time=3.451ms cpu_time=16.560us  self_cuda_time=36.266ms cuda_time=134.834us input_shapes= cpu_memory_usage=0 cuda_memory_usage=4523360256>,\n",
       " <FunctionEventAvg key=sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_execute_kernel_cudnn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=112.679ms cuda_time=563.395us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=sm75_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_execute_kernel_cudnn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=2.448s cuda_time=2.040ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=188.771ms cuda_time=269.673us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_128x256_ldg8_relu_f2f_stages_32x1_tn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=751.312ms cuda_time=375.656us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_64x64_sliced1x4_ldg8_f2f_tn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=22.941ms cuda_time=22.941us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_128x256_ldg8_relu_f2f_tn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=327.620ms cuda_time=655.240us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_64x128_sliced1x2_ldg8_f2f_tn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=30.696ms cuda_time=25.580us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_256x128_ldg8_relu_f2f_tn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=541.412ms cuda_time=902.353us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_execute_kernel_cudnn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=610.335ms cuda_time=435.954us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_128x64_sliced1x2_ldg8_f2f_tn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=20.032ms cuda_time=50.080us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_128x64_sliced1x2_ldg8_relu_f2f_tn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=15.179ms cuda_time=50.597us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_256x64_sliced1x2_ldg8_relu_f2f_tn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=16.714ms cuda_time=167.140us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=sm75_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_execute_kernel_cudnn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=49.547ms cuda_time=165.157us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::(anonymous namespace)::upsample_nearest2d_out_frame<c10::Half, &at::native::nearest_neighbor_compute_source_index>(c10::Half const*, c10::Half*, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, float, float) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=36.266ms cuda_time=119.690us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudnn_turing_fp16_s1688cudnn_fp16_256x128_ldg8_relu_filter1x1_stg8_interior_nchw_nn_v1 self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=29.555ms cuda_time=295.550us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_nn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=127.881ms cuda_time=426.270us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void tensorTransformGeneric<__half, __half, float, true, false, false, (cudnnKernelDataType_t)0>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, __half const*, __half*, float, float) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=1.691ms cuda_time=16.910us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=sm75_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_execute_kernel_cudnn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=19.022ms cuda_time=190.220us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::ge self_cpu_time=2.274ms cpu_time=29.860us  self_cuda_time=110.000us cuda_time=4.820us input_shapes= cpu_memory_usage=0 cuda_memory_usage=51200>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::compare_scalar_kernel<float>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::compare_scalar_kernel<float>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, float)::{lambda(float)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=51.000us cuda_time=1.020us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::is_nonzero self_cpu_time=263.000us cpu_time=43.720us  self_cuda_time=0.000us cuda_time=9.270us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::le self_cpu_time=1.013ms cpu_time=14.600us  self_cuda_time=100.000us cuda_time=38.220us input_shapes= cpu_memory_usage=0 cuda_memory_usage=51200>,\n",
       " <FunctionEventAvg key=aten::neg self_cpu_time=913.000us cpu_time=14.000us  self_cuda_time=100.000us cuda_time=4.780us input_shapes= cpu_memory_usage=0 cuda_memory_usage=51200>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=25.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float> >, at::detail::Array<char*, 3>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=105.000us cuda_time=1.050us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#2}>(int, at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#2}) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=830.000us cuda_time=4.150us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::unrolled_elementwise_kernel<at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=50.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::unrolled_elementwise_kernel<at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=152.000us cuda_time=1.013us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::unrolled_elementwise_kernel<at::native::compare_scalar_kernel<float>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, float)::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::compare_scalar_kernel<float>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, float)::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=105.000us cuda_time=1.050us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::unrolled_elementwise_kernel<at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=50.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::unrolled_elementwise_kernel<at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=50.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<2, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=25.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<2, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=75.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<2, at::native::compare_scalar_kernel<float>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::compare_scalar_kernel<float>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, float)::{lambda(float)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=54.000us cuda_time=1.080us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<2, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=26.000us cuda_time=1.040us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<2, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=25.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=25.000us cuda_time=1.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void cudnn::cnn::conv2d_grouped_direct_kernel<false, true, false, false, false, false, 4, 1, int, float, __half, __half, __half, float, __half>(cudnn::cnn::GroupedDirectFpropParams, __half const*, __half const*, __half*, float, float, float const*, float const*, __half const*, __half const*, cudnnActivationStruct) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=3.000us cuda_time=3.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::baddbmm self_cpu_time=46.000us cpu_time=212.000us  self_cuda_time=2.435ms cuda_time=2.435ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=169869312>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_128x256_ldg8_f2f_stages_32x1_tt self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=493.000us cuda_time=164.333us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1> >(int, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=1.400ms cuda_time=1.400ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::(anonymous namespace)::cunn_SoftMaxForward<4, float, float, float, at::native::(anonymous namespace)::SoftMaxForwardEpilogue>(float*, float*, int) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=3.417ms cuda_time=3.417ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=turing_fp16_s1688gemm_fp16_256x128_ldg8_f2f_stages_32x1_nn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=6.113ms cuda_time=2.038ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=aten::clamp self_cpu_time=25.000us cpu_time=31.000us  self_cuda_time=20.000us cuda_time=20.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=4194304>,\n",
       " <FunctionEventAvg key=sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_execute_kernel_cudnn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=58.994ms cuda_time=8.428ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=sm75_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_execute_kernel_cudnn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=26.123ms cuda_time=5.225ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=sm75_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc2_execute_kernel_cudnn self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=4.001ms cuda_time=4.001ms input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=20.000us cuda_time=20.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(c10::Half)#1}, at::detail::Array<char*, 2>) self_cpu_time=0.000us cpu_time=0.000us  self_cuda_time=20.000us cuda_time=20.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>,\n",
       " <FunctionEventAvg key=cudaDeviceSynchronize self_cpu_time=13.000us cpu_time=13.000us  self_cuda_time=0.000us cuda_time=0.000us input_shapes= cpu_memory_usage=0 cuda_memory_usage=0>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.key_averages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for si in [256, 512, 768]:\n",
    "    for st in [10, 50, 100, 200]:\n",
    "        df = pd.read_csv(f\"results/timings_{si}_{st}.csv\")\n",
    "        df[\"size\"] = si\n",
    "        df[\"steps\"] = st\n",
    "        dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "df[\"cpu_time_total\"] = df[\"cpu_time_total\"] / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='steps', ylabel='total_time'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGwCAYAAABcnuQpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/VElEQVR4nO3deXhU9b3H8c9kmewzIXsiSQiI7KCgjRFFhMhSa1FwQ1oBqVuDCqilVBGwVqzWfUHtVbDXKi4X5YoKNyCLSoiIICI1AgYTJAuL2ck65/5hGTsmhGSYyeTA+/U853kyv99vznxPTpjz4awWwzAMAQAAmJSfrwsAAAA4EYQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgagG+LsDbHA6H9u/fr4iICFksFl+XAwAA2sAwDFVWViopKUl+fq3veznpw8z+/fuVnJzs6zIAAIAbCgsL1bVr11bHnPRhJiIiQtKPvwybzebjagAAQFtUVFQoOTnZuR1vzUkfZo4eWrLZbIQZAABMpi2niHACMAAAMDXCDAAAMDXCDAAAMLWT/pyZtmpqalJDQ4Ovy+jUrFbrcS+PAwCgo53yYcYwDBUXF6usrMzXpXR6fn5+SktLk9Vq9XUpAAA4nfJh5miQiYuLU2hoKDfWO4ajNx8sKipSSkoKvycAQKdxSoeZpqYmZ5CJjo72dTmdXmxsrPbv36/GxkYFBgb6uhwAACSd4icAHz1HJjQ01MeVmMPRw0tNTU0+rgQAgJ+c0mHmKA6ZtA2/JwBAZ3RKH2YCAADuq6ioVO2ROoWEBCvCFu6zOggzAACgXSorqrTr62/17GOLtXdPgdJOT9XvZ05Vz95pCo/o+FDj08NM8+fPl8VicZl69+7t7K+trVVWVpaio6MVHh6uCRMmqKSkxIcVe8eUKVN02WWX+boMAACOq6G+QWtWbtCUK2/Vpxs/V2nJQeV+skWTr5iuNas+VkN9x9+zzed7Zvr166fVq1c7XwcE/FTSzJkz9d577+nNN9+U3W7X9OnTNX78eH3yySe+KNVrnnjiCRmG4esyAAA4rgMHDunB+U+22PfgvCf0i4yzlHhafIfW5PMwExAQoISEhGbt5eXlevHFF/Xqq69qxIgRkqTFixerT58+2rRpk84999wW51dXV6e6ujrn64qKCu8U7kF2u93XJQAA0CaHD/ygmuojLfZVV9Xo0MHDHR5mfH41065du5SUlKTu3btr0qRJKigokCRt2bJFDQ0NyszMdI7t3bu3UlJSlJOTc8z5LVy4UHa73TklJyd7fRna6q233tKAAQMUEhKi6OhoZWZmqrq62uUw0969e5sderNYLBo+fLhzPh9//LEuuOAChYSEKDk5Wbfddpuqq6t9s1AAgFOKn79/q/3+x+n3Bp+GmfT0dC1ZskQrV67UokWLlJ+frwsuuECVlZUqLi6W1WpVZGSky3vi4+NVXFx8zHnOmTNH5eXlzqmwsNDLS9E2RUVFmjhxoq6//nr961//0rp16zR+/Phmh5eSk5NVVFTknLZu3aro6GgNGzZMkrRnzx6NGTNGEyZM0Pbt2/X666/r448/1vTp032xWACAU0xUTKSioiNb7IuOjVKXY/R5k08PM40dO9b588CBA5Wenq7U1FS98cYbCgkJcWueQUFBCgoK8lSJHlNUVKTGxkaNHz9eqampkqQBAwY0G+fv7+887FZbW6vLLrtMGRkZmj9/vqQf9zxNmjRJM2bMkCT17NlTTz75pC688EItWrRIwcHBHbI8AIBTU1x8jB586l79/rq71Nj4001UAwID9OAT9yguPqbDa/L5OTP/KTIyUmeccYZ2796tiy++WPX19SorK3PZO1NSUtLiOTad3aBBgzRy5EgNGDBAo0eP1qhRo3TFFVeoS5cux3zP9ddfr8rKSmVnZzufVv3FF19o+/bt+uc//+kcZxiGHA6H8vPz1adPH68vCwDg1OXn56fB5wzUsv9bov9Z+p6+/mqX+vTvqfHXXKKkrgnO7VVH6lRhpqqqSnv27NFvf/tbDRkyRIGBgVqzZo0mTJggScrLy1NBQYEyMjJ8XGn7+fv7Kzs7Wxs3btT//d//6amnntLdd9+t3NzcFsfff//9WrVqlT799FNFREQ426uqqnTTTTfptttua/aelJQUr9UPAMBRVmuguvVI0Yw/3qj6unpZg6w+OVfmKJ+GmTvvvFOXXnqpUlNTtX//fs2bN0/+/v6aOHGi7Ha7pk2bplmzZikqKko2m0233nqrMjIyjnklU2dnsVg0dOhQDR06VPfee69SU1P19ttvNxv3P//zP7rvvvv0wQcfqEePHi59gwcP1s6dO3X66ad3VNkAALTI399fIaHunRbiST4NM/v27dPEiRN16NAhxcbG6vzzz9emTZsUGxsrSXrsscfk5+enCRMmqK6uTqNHj9azzz7ry5LdlpubqzVr1mjUqFGKi4tTbm6uDhw4oD59+mj79u3OcTt27NB1112n2bNnq1+/fs6Tna1Wq6KiojR79myde+65mj59un73u98pLCxMO3fuVHZ2tp5++mlfLR4AAD7j0zCzdOnSVvuDg4P1zDPP6JlnnumgirzHZrNpw4YNevzxx1VRUaHU1FQ98sgjGjt2rF5//XXnuM8++0w1NTW6//77df/99zvbL7zwQq1bt04DBw7U+vXrdffdd+uCCy6QYRjq0aOHrr76al8sFgAAPmcxTvJbz1ZUVMhut6u8vFw2m82lr7a2Vvn5+UpLS+MqoDbg9wUA6Citbb9/zuc3zQMAADgRhBkAAGBqhBkAAGBqhBkAAGBqhBkAAGBqhBkAAGBqhBkAAGBqhBkAAGBqhBkAAGBqhBkTWrhwoc455xxFREQoLi5Ol112mfLy8lzGDB8+XBaLxWW6+eabm81ryZIlGjhwoIKDgxUXF6esrKyOWgwAADzCp89mOlkYhqHG6ko5GhrkFxiogLAIWSwWr33e+vXrlZWVpXPOOUeNjY3605/+pFGjRmnnzp0KCwtzjrvhhht03333OV+Hhoa6zOfRRx/VI488oocffljp6emqrq7W3r17vVY3AADeQJg5QfXlP6h6f4GMhgZnmyUwUGFJKbLau3jlM1euXOnyesmSJYqLi9OWLVs0bNgwZ3toaKgSEhJanMcPP/yge+65R++++65GjhzpbB84cKBXagYAwFs4zHQC6st/UNV3e1yCjCQZDQ2q+m6P6st/6JA6ysvLJUlRUVEu7f/85z8VExOj/v37a86cOaqpqXH2ZWdny+Fw6Pvvv1efPn3UtWtXXXXVVSosLOyQmgEA8BT2zLjJMAxV7y9odUz1/gIF2iK9esjJ4XBoxowZGjp0qPr37+9sv/baa5WamqqkpCRt375ds2fPVl5enpYtWyZJ+vbbb+VwOPTAAw/oiSeekN1u1z333KOLL75Y27dvl9Vq9VrNAAB4EmHGTY3Vlc32yPyc0dCgxupKBYa3/ujyE5GVlaUdO3bo448/dmm/8cYbnT8PGDBAiYmJGjlypPbs2aMePXrI4XCooaFBTz75pEaNGiVJeu2115SQkKC1a9dq9OjRXqsZAABP4jCTmxzHCTLtHeeO6dOna8WKFVq7dq26du3a6tj09HRJ0u7duyVJiYmJkqS+ffs6x8TGxiomJkYFBa3vcQIAoDMhzLjJLzDQo+PawzAMTZ8+XW+//bY+/PBDpaWlHfc927Ztk/RTiBk6dKgkuVzSffjwYR08eFCpqakerxkAAG/hMJObAsIiZAkMbPVQk+Xfl2l7WlZWll599VUtX75cERERKi4uliTZ7XaFhIRoz549evXVV/XLX/5S0dHR2r59u2bOnKlhw4Y5r1Y644wzNG7cON1+++164YUXZLPZNGfOHPXu3VsXXXSRx2sGAMBb2DPjJovForCklFbHhCWleOXk30WLFqm8vFzDhw9XYmKic3r99dclSVarVatXr9aoUaPUu3dv3XHHHZowYYLeffddl/n84x//UHp6ui655BJdeOGFCgwM1MqVKxXohb1JAAB4i8UwDMPXRXhTRUWF7Ha7ysvLZbO5nohbW1ur/Px8paWlKTg42K35++I+M77iid8XAABt0dr2++c4zHSCrPYuCrRFdugdgAEAwE8IMx5gsVi8evk1AAA4Ns6ZAQAApkaYAQAApkaYAQAApkaYAQAApkaYAQAApkaYAQAApkaYAQAApkaYAQAApkaYMaH58+fLYrG4TL1793b2v/DCCxo+fLhsNpssFovKyspc3r93715NmzZNaWlpCgkJUY8ePTRv3jzV19d38JIAAHDiuAOwBzgcDh3c9b1qK6oVbAtTTM/T5Ofn3ZzYr18/rV692vk6IOCnVVlTU6MxY8ZozJgxmjNnTrP3fv3113I4HHr++ed1+umna8eOHbrhhhtUXV2tv/3tb16tGwAATyPMnKB9W3dr6+vrdKSsytkWEhmus64erq5nne61zw0ICFBCQkKLfTNmzJAkrVu3rsX+o0HnqO7duysvL0+LFi0izAAATIfDTCdg39bd2vj8CpcgI0lHyqq08fkV2rd1t9c+e9euXUpKSlL37t01adIkFRQUnND8ysvLFRUV5aHqAADoOIQZNzkcDm19fV2rY7a+sU4Oh8Pjn52enq4lS5Zo5cqVWrRokfLz83XBBReosrLSrfnt3r1bTz31lG666SYPVwoAgPdxmMlNB3d932yPzM8d+aFKB3d9r7heyR797LFjxzp/HjhwoNLT05Wamqo33nhD06ZNa9e8vv/+e40ZM0ZXXnmlbrjhBo/WCQBAR2DPjJtqK6o9Ou5EREZG6owzztDu3e07rLV//35ddNFFOu+88/TCCy94qToAALyLMOOmYFuYR8ediKqqKu3Zs0eJiYltfs/333+v4cOHa8iQIVq8eLHXr74CAMBbOMzkppiepykkMrzVQ00hXcIV0/M0j3/2nXfeqUsvvVSpqanav3+/5s2bJ39/f02cOFGSVFxcrOLiYueemi+//FIRERFKSUlRVFSUM8ikpqbqb3/7mw4cOOCc97GukAIAoLMizLjJz89PZ109XBufX3HMMWddNdwrezz27duniRMn6tChQ4qNjdX555+vTZs2KTY2VpL03HPPacGCBc7xw4YNkyQtXrxYU6ZMUXZ2tnbv3q3du3era9euLvM2DMPj9QIA4E0W4yTfelVUVMhut6u8vFw2m82lr7a2Vvn5+UpLS1NwcLBb82/xPjNdwnXWVd69z4wveOL3BQBAW7S2/f459sycoK5nna6kQd07/A7AAADgR4QZD/Dz8/P45dcAAKBt2H0AAABMjTADAABMjTADAABMjTADAABMjTADAABMjTADAABMjTADAABMjTADAABMjTBjUt26dZPFYmk2ZWVlOcfk5ORoxIgRCgsLk81m07Bhw3TkyBFn/zfffKNx48YpJiZGNptN559/vtauXeuLxQEAwG2EGQ9oamrS5pyten/5am3O2aqmpiavf+bmzZtVVFTknLKzsyVJV155paQfg8yYMWM0atQoffrpp9q8ebOmT5/u8piFX/3qV2psbNSHH36oLVu2aNCgQfrVr36l4uJir9cPAICn8KDJE3xw4uoPNuivC55USdEBZ1t8Yqxmz7tNmWOHnVDt7TFjxgytWLFCu3btksVi0bnnnquLL75Yf/7zn1scf/DgQcXGxmrDhg264IILJEmVlZWy2WzKzs5WZmZms/fwoEkAQEdpz4Mm2TNzAlZ/sEF33DLXJchIUmnxAd1xy1yt/mBDh9RRX1+vV155Rddff70sFotKS0uVm5uruLg4nXfeeYqPj9eFF16ojz/+2Pme6Oho9erVS//4xz9UXV2txsZGPf/884qLi9OQIUM6pG4AADyBMOOmpqYm/XXBk2ppv9bRtocWPNUhh5zeeecdlZWVacqUKZKkb7/9VpI0f/583XDDDVq5cqUGDx6skSNHateuXZIki8Wi1atXa+vWrYqIiFBwcLAeffRRrVy5Ul26dPF6zQAAeEqnCjMPPvigLBaLZsyY4Wyrra1VVlaWoqOjFR4ergkTJqikpMR3Rf7b559ub7ZH5j8ZhlRcVKrPP93u9VpefPFFjR07VklJSZIkh8MhSbrppps0depUnXXWWXrsscfUq1cvvfTSS/+uz1BWVpbi4uL00Ucf6dNPP9Vll12mSy+9VEVFRV6vGQAAT+k0YWbz5s16/vnnNXDgQJf2mTNn6t1339Wbb76p9evXa//+/Ro/fryPqvzJgdJDHh3nru+++06rV6/W7373O2dbYmKiJKlv374uY/v06aOCggJJ0ocffqgVK1Zo6dKlGjp0qAYPHqxnn31WISEhevnll71aMwAAntQpwkxVVZUmTZqkv//97y6HOMrLy/Xiiy/q0Ucf1YgRIzRkyBAtXrxYGzdu1KZNm3xYsRQbF+3Rce5avHix4uLidMkllzjbunXrpqSkJOXl5bmM/eabb5SamipJqqmpkSSXq5uOvj66ZwcAADPoFGEmKytLl1xySbMraLZs2aKGhgaX9t69eyslJUU5OTktzquurk4VFRUukzcM/sVAxSfGymJpud9ikRIS4zT4FwNbHuABDodDixcv1uTJkxUQEPAfn23RXXfdpSeffFJvvfWWdu/erblz5+rrr7/WtGnTJEkZGRnq0qWLJk+erC+++ELffPON7rrrLuXn57sEIwAAOruA4w/xrqVLl+rzzz/X5s2bm/UVFxfLarUqMjLSpT0+Pv6Y90JZuHChFixY4I1SXfj7+2v2vNt0xy1zZbHI5UTgowHnD/Nulb+/v9dqWL16tQoKCnT99dc365sxY4Zqa2s1c+ZMHT58WIMGDVJ2drZ69OghSYqJidHKlSt19913a8SIEWpoaFC/fv20fPlyDRo0yGs1AwDgaT4NM4WFhbr99tuVnZ3tsfuWzJkzR7NmzXK+rqioUHJyskfm/XOZY4fpkUV/bn6fmYQ4/WHerV6/z8yoUaPU2m2C/vjHP+qPf/zjMfvPPvtsrVq1yhulAQDQYXwaZrZs2aLS0lINHjzY2dbU1KQNGzbo6aef1qpVq1RfX6+ysjKXvTMlJSVKSEhocZ5BQUEKCgrydulOmWOH6aJRQ/X5p9t1oPSQYuOiNfgXA726RwYAAPzEp2Fm5MiR+vLLL13apk6dqt69e2v27NlKTk5WYGCg1qxZowkTJkiS8vLyVFBQoIyMDF+U3CJ/f3+dk3GWr8sAAOCU5NMwExERof79+7u0hYWFKTo62tk+bdo0zZo1S1FRUbLZbLr11luVkZGhc8891xclAwCATsbnJwAfz2OPPSY/Pz9NmDBBdXV1Gj16tJ599llflwUAADoJHjSZn69u3bopJCTERxWax5EjR7R3714eNAkA8DoeNNlGgYGBkn66gRxaV19fL0mc3AwA6FQ6/WEmb/L391dkZKRKS0slSaGhobIc6y54pziHw6EDBw4oNDTU5QZ9AAD42im/VTp6iffRQINj8/PzU0pKCoEPANCpnPJhxmKxKDExUXFxcWpoaPB1OZ2a1Wpt9iwnAAB87ZQPM0f5+/tzLggAACbEf7MBAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICpEWYAAICp+TTMLFq0SAMHDpTNZpPNZlNGRoY++OADZ39tba2ysrIUHR2t8PBwTZgwQSUlJT6sGAAAdDY+DTNdu3bVgw8+qC1btuizzz7TiBEjNG7cOH311VeSpJkzZ+rdd9/Vm2++qfXr12v//v0aP368L0sGAACdjMUwDMOdN+7Zs0eLFy/Wnj179MQTTyguLk4ffPCBUlJS1K9fP7cLioqK0sMPP6wrrrhCsbGxevXVV3XFFVdIkr7++mv16dNHOTk5Ovfcc9s0v4qKCtntdpWXl8tms7ldFwAA6Djt2X67tWdm/fr1GjBggHJzc7Vs2TJVVVVJkr744gvNmzfPnVmqqalJS5cuVXV1tTIyMrRlyxY1NDQoMzPTOaZ3795KSUlRTk7OMedTV1eniooKlwkAAJy83Aozf/zjH3X//fcrOztbVqvV2T5ixAht2rSpXfP68ssvFR4erqCgIN188816++231bdvXxUXF8tqtSoyMtJlfHx8vIqLi485v4ULF8putzun5OTkdtUDAADMxa0w8+WXX+ryyy9v1h4XF6eDBw+2a169evXStm3blJubq1tuuUWTJ0/Wzp073SlLkjRnzhyVl5c7p8LCQrfnBQAAOr8Ad94UGRmpoqIipaWlubRv3bpVp512WrvmZbVadfrpp0uShgwZos2bN+uJJ57Q1Vdfrfr6epWVlbnsnSkpKVFCQsIx5xcUFKSgoKB21QAAAMzLrT0z11xzjWbPnq3i4mJZLBY5HA598sknuvPOO3XdddedUEEOh0N1dXUaMmSIAgMDtWbNGmdfXl6eCgoKlJGRcUKfAQAATh5u7Zl54IEHlJWVpeTkZDU1Nalv375qamrStddeq3vuuafN85kzZ47Gjh2rlJQUVVZW6tVXX9W6deu0atUq2e12TZs2TbNmzVJUVJRsNptuvfVWZWRktPlKJgAAcPJzK8xYrVb9/e9/19y5c7Vjxw5VVVXprLPOUs+ePds1n9LSUl133XUqKiqS3W7XwIEDtWrVKl188cWSpMcee0x+fn6aMGGC6urqNHr0aD377LPulAwAAE5Sbt9nxiy4zwwAAObTnu23W3tmDMPQW2+9pbVr16q0tFQOh8Olf9myZe7MFgAAoN3cCjMzZszQ888/r4suukjx8fGyWCyergsAAKBN3Aoz//3f/61ly5bpl7/8pafrAQAAaBe3Ls222+3q3r27p2sBAABoN7fCzPz587VgwQIdOXLE0/UAAAC0i1uHma666iq99tpriouLU7du3RQYGOjS//nnn3ukOAAAgONxK8xMnjxZW7Zs0W9+8xtOAAYAAD7lVph57733tGrVKp1//vmergcAAKBd3DpnJjk5mRvQAQCATsGtMPPII4/oD3/4g/bu3evhcgAAANrHrcNMv/nNb1RTU6MePXooNDS02QnAhw8f9khxAAAAx+NWmHn88cc9XAYAAIB73L6aCQAAoDNoc5ipqKhwnvRbUVHR6lhODgYAAB2lzWGmS5cuKioqUlxcnCIjI1u8t4xhGLJYLGpqavJokQAAAMfS5jDz4YcfKioqSpK0du1arxUEAADQHm0OMxdeeKHz57S0NCUnJzfbO2MYhgoLCz1XHQAAwHG4dZ+ZtLQ0HThwoFn74cOHlZaWdsJFAQAAtJVbYebouTE/V1VVpeDg4BMuCgAAoK3adWn2rFmzJEkWi0Vz585VaGios6+pqUm5ubk688wzPVogAABAa9oVZrZu3Srpxz0zX375paxWq7PParVq0KBBuvPOOz1bIYBTQlNTkw4d/EGGw1CELVyhYSG+LgmASbQrzBy9imnq1Kl64oknjns/mX379ikpKUl+fm4dzQJwiigtPqjlb32gpS+/rerqGg0dnq6smdcrJe00BQS4dW9PAKcQi2EYhrdmbrPZtG3bNnXv3t1bH3FcFRUVstvtKi8v52Z+QCd0oPSQZt44V9u3fuXSHhwcpNfefUE9zujmm8IA+FR7tt9e3WXixZwE4CSx55v8ZkFGkmpr6/TU3/6u6qpqH1QFwEw4/gPAp1atOPZNODesyVFlJWEGQOsIMwB8KsIWfsy+kNCQFm8DAQD/iTADwKcuueziY/ZdMfFXioqO7LhiAJiSV8MM/6MCcDyJp8Xrptuua9Z++hlpmjhlggIDA31QFQAz8eo1j5wADOB4bPYI/WbalRox+gIte/19lR0u09hxmeo/sJfiEmJ9XR4AE/BqmNm5c6eSkpK8+REATgL2SJvskTbd3f+MYz4uBQCOpc1hZvz48W2e6bJlyyRJycnJ7a8IwCmNIAOgvdocZux2uzfrAAAAcEubw8zixYu9WQcAAIBbuDQbAACYmtsnAL/11lt64403VFBQoPr6epe+zz///IQLAwAAaAu39sw8+eSTmjp1quLj47V161b94he/UHR0tL799luNHTvW0zUCAAAck1th5tlnn9ULL7ygp556SlarVX/4wx+UnZ2t2267TeXl5Z6uEQAA4JjcCjMFBQU677zzJEkhISGqrKyUJP32t7/Va6+95rnqAAAAjsOtMJOQkKDDhw9LklJSUrRp0yZJUn5+Pnf9BQAAHcqtMDNixAj97//+ryRp6tSpmjlzpi6++GJdffXVuvzyyz1aIAAAQGsshhu7UhwOhxwOhwICfrwYaunSpdq4caN69uypm266SVar1eOFuquiokJ2u13l5eWy2Wy+LgcAALRBe7bfboWZgoICJScnN7vtuGEYKiwsVEpKSntn6TWEGQAAzKc922+3DjOlpaXpwIEDzdoPHz6stLQ0d2YJAADgFrfCzLGealtVVaXg4OATLgoAAKCt2nUH4FmzZkn68am2c+fOVWhoqLOvqalJubm5OvPMMz1aIAAAQGvaFWa2bt0q6cc9M19++aXLib5Wq1WDBg3SnXfe6dkKAQAAWtGuMLN27VpJP16O/cQTT3BCLQAA8Dm3HjS5ePFi58/79u2TJHXt2tUzFQEAALSDWycAOxwO3XfffbLb7UpNTVVqaqoiIyP15z//WQ6Hw9M1AgAAHJNbe2buvvtuvfjii3rwwQc1dOhQSdLHH3+s+fPnq7a2Vn/5y188WiQAAMCxuHXTvKSkJD333HP69a9/7dK+fPly/f73v9f333/vsQJPFDfNAwDAfLx+07zDhw+rd+/ezdp79+7tfAAlAABAR3ArzAwaNEhPP/10s/ann35agwYNOuGiAAAA2sqtc2YeeughXXLJJVq9erUyMjIkSTk5OSosLNT777/v0QIBAABa4/azmb755htdfvnlKisrU1lZmcaPH6+8vDylpqZ6ukYAAIBjcusEYH9/fxUVFSkuLs6l/dChQ4qLi1NTU5PHCjxRnAAMAID5eP0E4GPlHx40CQAAOprbD5q89957edAkAACnqMa6BtVW1qixtl4BQVYF20IVEBTok1p8+qDJhQsXatmyZfr6668VEhKi8847T3/961/Vq1cv55ja2lrdcccdWrp0qerq6jR69Gg9++yzio+Pb0/pAADAQ46UVemrFZuUv3GnDIdDfv5+6pbRV/1+da5CIsM7vB63zpnx1IMmx4wZo2uuuUbnnHOOGhsb9ac//Uk7duzQzp07FRYWJkm65ZZb9N5772nJkiWy2+2aPn26/Pz89Mknn7TpMzhnBgAAz2k4UqfP/rlGhZ9906wv5ZxeGnztCFlDgk74c9qz/XYrzHjLgQMHFBcXp/Xr12vYsGEqLy9XbGysXn31VV1xxRWSpK+//lp9+vRRTk6Ozj333OPOkzADAIDnVJb+oA/mvSy1lB4s0tgFkxUR1+WEP8frJwB7S3l5uSQpKipKkrRlyxY1NDQoMzPTOaZ3795KSUlRTk5Oi/Ooq6tTRUWFywQAADyjvrq25SAjSca/+ztYpwkzDodDM2bM0NChQ9W/f39JUnFxsaxWqyIjI13GxsfHq7i4uMX5LFy4UHa73TklJyd7u3QAAE4ZAUHW1vuDW+/3hk4TZrKysrRjxw4tXbr0hOYzZ84clZeXO6fCwkIPVQgAAIIiQhXVreWLcKK6JSgoPKSDK+okYWb69OlasWKF1q5dq65duzrbExISVF9fr7KyMpfxJSUlSkhIaHFeQUFBstlsLhMAAPCM4IgQnfu7X8qWFO3Sbk+K1rm/G6vgiNBjvNN73Ho2k6cYhqFbb71Vb7/9ttatW6e0tDSX/iFDhigwMFBr1qzRhAkTJEl5eXkqKChwPhMKAAB0rPAYu4bfPl415VU6crhKIVHhCo0MV7AtzCf1+DTMZGVl6dVXX9Xy5csVERHhPA/GbrcrJCREdrtd06ZN06xZsxQVFSWbzaZbb71VGRkZbbqSCQAAeEewPUzB9jApxff3ffPppdkWi6XF9sWLF2vKlCmSfrpp3muvveZy07xjHWb6OS7NBgDAfEx7nxlvIMwAAGA+pr3PDAAAQHsRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkRZgAAgKkF+LoAoD2O1NTq4IFDqq4+orCwEEXHRCk0LMTXZQEAfIgwA9M4UHJIzzz6kv73rQ/U2Ngkf39//XJcpm6ffaPiEmJ8XR4AwEc4zARTqKqs1mMLF2nZ0hVqbGySJDU1NendZau0cN4Tqiiv9HGFAABfIczAFA4f+kHvL1/TYt+alRt0+FBZxxYEAOg0CDMwhfKySjkcjmP3/1DegdUAADoTwgxMISw8tPX+iLAOqgQA0NkQZmAKUdFdNPicgS329R3QS1HRkR1bEACg0yDMwBQiu9j0wON3q0//M1zae/bqrr8tWqCo6C4+qgwA4Gtcmg3TSOqaoGdffkgHSg+qtPigYuNiFBsfrZjYKF+XBgDwIcIMTCU6pouiY7qod9+evi4FANBJcJgJAACYGmEGAACYGmEGAACYGmEGAACYGmEGAACYGmEGAACYGmEGAACYGmEGAACYGmEGAACYGncABuBzDodDtWXVOlJWpcb6BoVF2xQUEaLA4CBflwbABAgzAHyqqbFJh/OL9MlzK1RfXStJsvhZdEbmYPW6eIiCI0J9XCGAzs6nh5k2bNigSy+9VElJSbJYLHrnnXdc+g3D0L333qvExESFhIQoMzNTu3bt8k2xALziyA+VWv/E284gI0mGw1De/21R8Vd7fVcYANPwaZiprq7WoEGD9Mwzz7TY/9BDD+nJJ5/Uc889p9zcXIWFhWn06NGqra1tcTwA89m//Vs5Gpta7PtqRa6OlFd3cEUAzManh5nGjh2rsWPHtthnGIYef/xx3XPPPRo3bpwk6R//+Ifi4+P1zjvv6JprrmnxfXV1daqrq3O+rqio8HzhADymbN/BY/bVHKqQ4XB0YDUAzKjTXs2Un5+v4uJiZWZmOtvsdrvS09OVk5NzzPctXLhQdrvdOSUnJ3dEuQDcFHN60jH7bEnR8gvw78BqAJhRpw0zxcXFkqT4+HiX9vj4eGdfS+bMmaPy8nLnVFhY6NU6AZyY+N4pCgxt+aqlgZcP5QRgAMfVacOMu4KCgmSz2VwmAJ1XaFSELpp1pWyJUc62wJAgnf2bTEV1T/RhZQDMotNemp2QkCBJKikpUWLiT19oJSUlOvPMM31UFQBPs1gsiuwao+Ezr1Bd1RE5mpoUFBaiYHuo/Pw5xATg+Drtnpm0tDQlJCRozZo1zraKigrl5uYqIyPDh5UB8IZgW6jsSdHqkhyn0KgIggyANvPpnpmqqirt3r3b+To/P1/btm1TVFSUUlJSNGPGDN1///3q2bOn0tLSNHfuXCUlJemyyy7zXdEAAECOhgY5GhtlNDbIEhgoP/8A+QUG+qQWn4aZzz77TBdddJHz9axZsyRJkydP1pIlS/SHP/xB1dXVuvHGG1VWVqbzzz9fK1euVHBwsK9KBgDglNdUX6eq775V05Gf7gPlHxKm8NTu8rd2/GNILIZhGB3+qR2ooqJCdrtd5eXlnAwMAMAJcjQ2qmrvbjXWVDXrCwgNV3i30+UXcOL7Stqz/e6058wAAIDOx2hsaDHISFJjTZWMxoYOrogwAwAA2sFwtPz4kbb2ewNhBgAAtJnFr/VDSBb/jj8dlzADAADazBIQoEBbZIt9gbZIwgwAAOjc/AICFJaUokB7F5f2QHsXhZ2W4pGTf9ur094BGAAAdE5+VqvCunaTkXCajKYmWfz9ZQkI9NnNLgkzAACg3fz8/aVOcqduDjMBAABTI8wAAABTI8wAAABTI8wAAABTI8wAAABTI8wAAABTI8wAAABTI8wAAABTI8wAAABTI8wAAABTI8wAAABTI8wAAABTI8wAAABTI8wAAABTC/B1AUB7NBypV11VjeqP1Csw2KqgiBBZQ4J8XRYAwIcIMzCNI2VV+uJ/PlLhZ9/IMAzJInU9q6fOvHKYQrtE+Lo8AICPcJgJptBwpE5b31ivgs15PwYZSTKkfZ/v0pZXP1R9da1vCwQA+AxhBqZQW1GjfVt3tdhX9GW+aitrOrgiAEBnQZiBKdQfqZOMVvrZMwMApyzOmYEpBAZbW+8P5SRgszMcDjkaGyUZsvj5yy+ArycAbcO3BUwhKCJEcb2SVZpX2KwvunuigsJDfFAVPKWpvk61pcWq++GgZBgKCA1XaFKy/IODZfHz93V5ADo5DjPBFILCQvSLyRcrunuiS3uX1DidO22sgiNCfVQZTlRTfb0q83ep7vAB6d8ndzfWVKli99dqquPwIYDjY88MTCM0yqaht/xadZU1qq2oUXBEiIJsoQQZk2uqrZGjxdBiqKZon8JTenDICUCr+IaAqQRHhCg4IkT2pGhflwIPqS//4Zh9jVWVMhyODqwGgBlxmAmAT/kFBh6zz+IfIEsH1gLAnAgzAHzKGnnsvWxB0XGytBJ2AEAizADwMb/AQIUmpTRr9w8NV3B0jCwW9s0AaB3nzADwKT//AFm7RCkwPEL1FWUympoUGGGXX1Bwq4egAOAowgwAn/PzD5D8AxQSzP2CALQfYcYNDodDB0oOqba2TlZroGLiohTI/yABAPAJwkw7/XC4TGtWfqRnH3tJB0sPKyw8VBOnjNe1k8crJo7LhQEA6GicANwODQ0N+t+3Vuq+OX/TwdLDkqTqqhr919Ov6K8LnlJ5WYWPKwQA4NRDmGmHAyWHtOjxJS32rVqxVocPlXVoPQAAgDDTLpUVVaqpPnLM/sLvvu/AagAAgMQ5M+0SFGRttd9uj+igSk5dhsMhR0ODDEeTLH5+sgQGyo+nKgPAKY0w0w5doiM1JH2QtuR+0awvKqaL4pPifFDVqcPRUK8jpcU/PV3ZYpG1S7RC4pPkH9h60AQAnLw4zNQO9kib7nv4jzotOdGlPcIWrmeX/FXxCbE+quzk52hqUk3x96o7VPpjkJEkw1D94YOq2V8oR1OjbwsEAPgMe2baKTk1SUveekp79xTqXzu+UUraaerdr6cSEuO47boXGY0Nqv/hUIt9DeU/yEg4TfLnzxkATkV8+7shPiFW8QmxSh862NelnDKMpqZW+x2NjfIP6qBiAACdCoeZYAoWv9b/VC2cBAwApyzCjJsa6xp0pKJa9UfqfF3KKcESECD/0LAW+/yDQ+QXwE5GADhVsQVop8b6BlWVlulfqzbrh+9KFRZtV99fniP7aTGyhgb7uryTll9AoMKTu6ty7y456mp/arcGKTy1B09XBoBTGGGmnQ7u3q+PnnpHxr+vqKkqLVPJv77TmVdeqO4X9FeAlY2qt/gHBSmiey8ZDfVqqq+Tv9Uqv8AfJwDAqYvDTO1QU1apz/57tTPI/Kftyz5SbXm1D6o6tfgHBiogNExBkVEKCA0nyAAACDPtUV9Vq5ofKlvsczQ5VFVa1rEFAQAAwoxHcZ8ZAAA6HGGmHayhQQqPtbfY5x/or/AYWwdXBAAACDPtEBwRrLN/M0J+Ac3vaXLW1cMVFMHVTAAAdDSuZmoHv0CrIrvGKHP2VcrP2anDe0sVHmvX6cP6KzQqTAFB3IIWAICORphpp8DQUEUE+Kv3iP5qrKuXvzVA1ogI+VmDjnuXWgAA4Hmm2Po+88wz6tatm4KDg5Wenq5PP/3UZ7VYLBb5BwUrODpGYQkJComJVUBwqPy4nT4AAD7R6cPM66+/rlmzZmnevHn6/PPPNWjQII0ePVqlpaU+rctiscjP318WS6f/FQIAcFLr9FviRx99VDfccIOmTp2qvn376rnnnlNoaKheeuklX5cGAAA6gU4dZurr67VlyxZlZmY62/z8/JSZmamcnJwW31NXV6eKigqXCQAAnLw6dZg5ePCgmpqaFB8f79IeHx+v4uLiFt+zcOFC2e1255ScnNwRpQIAAB/p1GHGHXPmzFF5eblzKiws9HVJAADAizr1pdkxMTHy9/dXSUmJS3tJSYkSEhJafE9QUJCCuN8LAACnjE69Z8ZqtWrIkCFas2aNs83hcGjNmjXKyMjwYWUAAKCz6NR7ZiRp1qxZmjx5ss4++2z94he/0OOPP67q6mpNnTrV16UBAIBOoNOHmauvvloHDhzQvffeq+LiYp155plauXJls5OCAQDAqcliGIbh6yK8qaKiQna7XeXl5bLZeKo1AABm0J7td6c+ZwYAAOB4Ov1hphN1dMcTN88DAMA8jm6323IA6aQPM5WVlZLEzfMAADChyspK2e32Vsec9OfMOBwO7d+/XxEREbJYLL4ux2sqKiqUnJyswsLCU+LcoFNpeVnWk9eptLws68nJm8tqGIYqKyuVlJQkP7/Wz4o56ffM+Pn5qWvXrr4uo8PYbLaT/h/PfzqVlpdlPXmdSsvLsp6cvLWsx9sjcxQnAAMAAFMjzAAAAFMjzJwkgoKCNG/evFPmuVSn0vKyrCevU2l5WdaTU2dZ1pP+BGAAAHByY88MAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcKMiSxcuFDnnHOOIiIiFBcXp8suu0x5eXkuY4YPHy6LxeIy3XzzzT6q+MTMnz+/2bL07t3b2V9bW6usrCxFR0crPDxcEyZMUElJiQ8rdl+3bt2aLavFYlFWVpYk86/XDRs26NJLL1VSUpIsFoveeecdl37DMHTvvfcqMTFRISEhyszM1K5du1zGHD58WJMmTZLNZlNkZKSmTZumqqqqDlyKtmltWRsaGjR79mwNGDBAYWFhSkpK0nXXXaf9+/e7zKOlv4cHH3ywg5fk+I63XqdMmdJsOcaMGeMyxizrVTr+8rb0b9hisejhhx92jjHDum3LtqYt378FBQW65JJLFBoaqri4ON11111qbGz0Ss2EGRNZv369srKytGnTJmVnZ6uhoUGjRo1SdXW1y7gbbrhBRUVFzumhhx7yUcUnrl+/fi7L8vHHHzv7Zs6cqXfffVdvvvmm1q9fr/3792v8+PE+rNZ9mzdvdlnO7OxsSdKVV17pHGPm9VpdXa1BgwbpmWeeabH/oYce0pNPPqnnnntOubm5CgsL0+jRo1VbW+scM2nSJH311VfKzs7WihUrtGHDBt14440dtQht1tqy1tTU6PPPP9fcuXP1+eefa9myZcrLy9Ovf/3rZmPvu+8+l/V96623dkT57XK89SpJY8aMcVmO1157zaXfLOtVOv7y/udyFhUV6aWXXpLFYtGECRNcxnX2dduWbc3xvn+bmpp0ySWXqL6+Xhs3btTLL7+sJUuW6N577/VO0QZMq7S01JBkrF+/3tl24YUXGrfffrvvivKgefPmGYMGDWqxr6yszAgMDDTefPNNZ9u//vUvQ5KRk5PTQRV6z+2332706NHDcDgchmGcXOtVkvH22287XzscDiMhIcF4+OGHnW1lZWVGUFCQ8dprrxmGYRg7d+40JBmbN292jvnggw8Mi8VifP/99x1We3v9fFlb8umnnxqSjO+++87Zlpqaajz22GPeLc7DWlrWyZMnG+PGjTvme8y6Xg2jbet23LhxxogRI1zazLhuf76tacv37/vvv2/4+fkZxcXFzjGLFi0ybDabUVdX5/Ea2TNjYuXl5ZKkqKgol/Z//vOfiomJUf/+/TVnzhzV1NT4ojyP2LVrl5KSktS9e3dNmjRJBQUFkqQtW7aooaFBmZmZzrG9e/dWSkqKcnJyfFWuR9TX1+uVV17R9ddf7/Jw1JNpvf6n/Px8FRcXu6xLu92u9PR057rMyclRZGSkzj77bOeYzMxM+fn5KTc3t8Nr9qTy8nJZLBZFRka6tD/44IOKjo7WWWedpYcffthru+e9bd26dYqLi1OvXr10yy236NChQ86+k3m9lpSU6L333tO0adOa9Zlt3f58W9OW79+cnBwNGDBA8fHxzjGjR49WRUWFvvrqK4/XeNI/aPJk5XA4NGPGDA0dOlT9+/d3tl977bVKTU1VUlKStm/frtmzZysvL0/Lli3zYbXuSU9P15IlS9SrVy8VFRVpwYIFuuCCC7Rjxw4VFxfLarU22wDEx8eruLjYNwV7yDvvvKOysjJNmTLF2XYyrdefO7q+/vNL7+jro33FxcWKi4tz6Q8ICFBUVJSp13dtba1mz56tiRMnujyk77bbbtPgwYMVFRWljRs3as6cOSoqKtKjjz7qw2rbb8yYMRo/frzS0tK0Z88e/elPf9LYsWOVk5Mjf3//k3a9StLLL7+siIiIZoe+zbZuW9rWtOX7t7i4uMV/00f7PI0wY1JZWVnasWOHyzkkklyONQ8YMECJiYkaOXKk9uzZox49enR0mSdk7Nixzp8HDhyo9PR0paam6o033lBISIgPK/OuF198UWPHjlVSUpKz7WRar/hRQ0ODrrrqKhmGoUWLFrn0zZo1y/nzwIEDZbVaddNNN2nhwoU+v218e1xzzTXOnwcMGKCBAweqR48eWrdunUaOHOnDyrzvpZde0qRJkxQcHOzSbrZ1e6xtTWfDYSYTmj59ulasWKG1a9eqa9eurY5NT0+XJO3evbsjSvOqyMhInXHGGdq9e7cSEhJUX1+vsrIylzElJSVKSEjwTYEe8N1332n16tX63e9+1+q4k2m9Hl1fP78S4j/XZUJCgkpLS136GxsbdfjwYVOu76NB5rvvvlN2drbLXpmWpKenq7GxUXv37u2YAr2ke/fuiomJcf7dnmzr9aiPPvpIeXl5x/13LHXudXusbU1bvn8TEhJa/Dd9tM/TCDMmYhiGpk+frrffflsffvih0tLSjvuebdu2SZISExO9XJ33VVVVac+ePUpMTNSQIUMUGBioNWvWOPvz8vJUUFCgjIwMH1Z5YhYvXqy4uDhdcsklrY47mdZrWlqaEhISXNZlRUWFcnNznesyIyNDZWVl2rJli3PMhx9+KIfD4Qx2ZnE0yOzatUurV69WdHT0cd+zbds2+fn5NTskYzb79u3ToUOHnH+3J9N6/U8vvviihgwZokGDBh13bGdct8fb1rTl+zcjI0NffvmlS1g9Gtz79u3rlaJhErfccotht9uNdevWGUVFRc6ppqbGMAzD2L17t3HfffcZn332mZGfn28sX77c6N69uzFs2DAfV+6eO+64w1i3bp2Rn59vfPLJJ0ZmZqYRExNjlJaWGoZhGDfffLORkpJifPjhh8Znn31mZGRkGBkZGT6u2n1NTU1GSkqKMXv2bJf2k2G9VlZWGlu3bjW2bt1qSDIeffRRY+vWrc4reB588EEjMjLSWL58ubF9+3Zj3LhxRlpamnHkyBHnPMaMGWOcddZZRm5urvHxxx8bPXv2NCZOnOirRTqm1pa1vr7e+PWvf2107drV2LZtm8u/46NXeGzcuNF47LHHjG3bthl79uwxXnnlFSM2Nta47rrrfLxkzbW2rJWVlcadd95p5OTkGPn5+cbq1auNwYMHGz179jRqa2ud8zDLejWM4/8dG4ZhlJeXG6GhocaiRYuavd8s6/Z42xrDOP73b2Njo9G/f39j1KhRxrZt24yVK1casbGxxpw5c7xSM2HGRCS1OC1evNgwDMMoKCgwhg0bZkRFRRlBQUHG6aefbtx1111GeXm5bwt309VXX20kJiYaVqvVOO2004yrr77a2L17t7P/yJEjxu9//3ujS5cuRmhoqHH55ZcbRUVFPqz4xKxatcqQZOTl5bm0nwzrde3atS3+7U6ePNkwjB8vz547d64RHx9vBAUFGSNHjmz2ezh06JAxceJEIzw83LDZbMbUqVONyspKHyxN61pb1vz8/GP+O167dq1hGIaxZcsWIz093bDb7UZwcLDRp08f44EHHnAJAJ1Fa8taU1NjjBo1yoiNjTUCAwON1NRU44YbbnC5VNcwzLNeDeP4f8eGYRjPP/+8ERISYpSVlTV7v1nW7fG2NYbRtu/fvXv3GmPHjjVCQkKMmJgY44477jAaGhq8UrPl34UDAACYEufMAAAAUyPMAAAAUyPMAAAAUyPMAAAAUyPMAAAAUyPMAAAAUyPMAAAAUyPMAAAAUyPMAAAAUyPMAOh0pkyZossuu8zXZQAwCcIMAAAwNcIMAJ956623NGDAAIWEhCg6OlqZmZm666679PLLL2v58uWyWCyyWCxat26dJKmwsFBXXXWVIiMjFRUVpXHjxmnv3r3O+R3do7NgwQLFxsbKZrPp5ptvVn19faufWV1d3cFLDsCTAnxdAIBTU1FRkSZOnKiHHnpIl19+uSorK/XRRx/puuuuU0FBgSoqKrR48WJJUlRUlBoaGjR69GhlZGToo48+UkBAgO6//36NGTNG27dvl9VqlSStWbNGwcHBWrdunfbu3aupU6cqOjpaf/nLX475mTxvFzA3wgwAnygqKlJjY6PGjx+v1NRUSdKAAQMkSSEhIaqrq1NCQoJz/CuvvCKHw6H/+q//ksVikSQtXrxYkZGRWrdunUaNGiVJslqteumllxQaGqp+/frpvvvu01133aU///nPrX4mAPPiMBMAnxg0aJBGjhypAQMG6Morr9Tf//53/fDDD8cc/8UXX2j37t2KiIhQeHi4wsPDFRUVpdraWu3Zs8dlvqGhoc7XGRkZqqqqUmFhYbs/E4A5EGYA+IS/v7+ys7P1wQcfqG/fvnrqqafUq1cv5efntzi+qqpKQ4YM0bZt21ymb775Rtdee61XPhOAORBmAPiMxWLR0KFDtWDBAm3dulVWq1Vvv/22rFarmpqaXMYOHjxYu3btUlxcnE4//XSXyW63O8d98cUXOnLkiPP1pk2bFB4eruTk5FY/E4B5EWYA+ERubq4eeOABffbZZyooKNCyZct04MAB9enTR926ddP27duVl5engwcPqqGhQZMmTVJMTIzGjRunjz76SPn5+Vq3bp1uu+027du3zznf+vp6TZs2TTt37tT777+vefPmafr06fLz82v1MwGYFycAA/AJm82mDRs26PHHH1dFRYVSU1P1yCOPaOzYsTr77LO1bt06nX322aqqqtLatWs1fPhwbdiwQbNnz9b48eNVWVmp0047TSNHjpTNZnPOd+TIkerZs6eGDRumuro6TZw4UfPnzz/uZwIwL4vBNYkAThJTpkxRWVmZ3nnnHV+XAqADcZgJAACYGmEGAACYGoeZAACAqbFnBgAAmBphBgAAmBphBgAAmBphBgAAmBphBgAAmBphBgAAmBphBgAAmBphBgAAmNr/A9r1w5GRrfW5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=df, x=\"steps\", y=\"total_time\", hue=\"size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
